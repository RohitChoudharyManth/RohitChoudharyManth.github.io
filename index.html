<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Rohit Choudhary</title>

    <meta name="author" content="Rohit Choudhary">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Rohit Choudhary
                </p>
                <p>I am a M.S. research scholar at department of <a href="https://www.ee.iitm.ac.in/">Electrical Engineering</a>, <a href="https://www.iitm.ac.in/">IIT Madras</a>, where I am working under the guidance of <a href="https://www.ee.iitm.ac.in/kmitra/">Dr. Kaushik Mitra</a> and <a href="https://www.linkedin.com/in/mansi-sharma-89942623/?originalSubdomain=in">Dr. Mansi Sharma</a>. I am working on developing deep learning methods for low-light image enhancement and scene depth estimation. Prior to joining the M.S program at IIT Madras, I completed my undergraduate studies in Electronics and Communication Engineering from the National Institute of Technology Kurukshetra, India.
                </p>
                <p style="text-align:center">
                  <a href="mailto:rohitchoudharymanth@gmail.com">Email</a> &nbsp;/&nbsp;
                  <a href="">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?view_op=list_works&hl=en&user=IQZ4jIQAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/rohit-c-02051b148/">LinkedIn</a> &nbsp;/&nbsp;
                  <a href="https://github.com/RohitChoudharyManth">Github</a>
                </p>
              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <a href="images/rohit_pic.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/rohit_pic_c.png" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h4><font color="red"<strong>News</strong></font></h4>
                <p>
                   <ul>
                    <li>(June 17, 2024) See you at Arch Building Exhibit Hall, Board 56 <font color ="red">(Poster Presentation)</font> at 3DMV, CVPR 2024.</li>
                    <li>(October 9, 2023) I will be presenting ELEGAN <font color ="red">(Poster Presentation)</font> at ICIP 2023.</li>
                    <li>(June 22, 2023) Paper on unsupervised low light image enhancement accepted in IEEE ICIP 2023.</li>
                    <li>(April 27, 2023) MEStereo-Du2CNN paper accepted for publication in The Visual Computer Journal.</li>
                    <li>(September, 2021) Paper on stereo depth estimation accepted in IEEE VCIP 2021.</li>

                  </ul> 
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  I'm interested in computer vision, machine learning and image processing. Most of my research has been focused on advancing scene depth estimation and low light image enhancement.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          
            

            <tr onmouseout="hnerf_stop()" onmouseover="hnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='blocknerf_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/GANESH.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/Ganesh.png' width="160">
                </div>
                  <script type="text/javascript">
                  function hnerf_start() {
                    document.getElementById('hnerf_image').style.opacity = "1";
                  }

                  function hnerf_stop() {
                    document.getElementById('hnerf_image').style.opacity = "0";
                  }
                  hnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2210.15374">
                  <span class="papertitle">GANESH: Generalizable NeRF for Lensless Imaging</span>
                </a>
                <br>
                Rakesh Raj Madavan, Akshat Kaimal, Badhrinarayanan K V, Vinayak Gupta, <strong>Rohit Choudhary</strong>, Chandrakala Shanmuganathan, Kaushik Mitra. 
                <br> <em>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV)</em> 2025.
                <br>
                 <a href="hhttps://arxiv.org/pdf/2411.04810">Arxiv Link/</a>
                <a href="https://rakesh-123-cryp.github.io/Rakesh.github.io/static/index.html">Project page</a>
                <p></p>
                <p>Framework for simultaneous 3D refinement and novel view synthesis from multi-view lensless images, supporting on-the-fly inference and scene-specific tuning.</p>
              </td>
            </tr>


            <tr onmouseout="hnerf_stop()" onmouseover="hnerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='blocknerf_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/2tunet.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/2t.png' width="160">
                </div>
                  <script type="text/javascript">
                  function hnerf_start() {
                    document.getElementById('hnerf_image').style.opacity = "1";
                  }

                  function hnerf_stop() {
                    document.getElementById('hnerf_image').style.opacity = "0";
                  }
                  hnerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2210.15374">
                  <span class="papertitle">2T-UNET: A Two-Tower UNet with Depth Clues for Robust Stereo Depth Estimation</span>
                </a>
                <br>
                <strong>Rohit Choudhary*</strong>,
                <a href="https://www.linkedin.com/in/mansi-sharma-89942623/?originalSubdomain=in">Mansi Sharma*</a>,
                <a href="https://www.linkedin.com/in/rithvik-anil/?originalSubdomain=in">Rithvik Anil</a>, 
                <br> <em>Second Workshop for Learning 3D with Multi-View Supervision (3DMV), CVPR</em> 2024.
                <br>
                 <a href="https://openaccess.thecvf.com/content/CVPR2024W/3DMV/papers/Sharma_2T-UNET_A_Two-Tower_UNet_with_Depth_Clues_for_Robust_Stereo_CVPRW_2024_paper.pdf">Paper Link/</a>
                <a href="https://arxiv.org/abs/2210.15374">ArXiv</a>
                <p></p>
                <p>Robust stereo depth estimation perform incredibly well on complex natural scenes.</p>
              </td>
            </tr>

      <tr onmouseout="zipnerf_stop()" onmouseover="zipnerf_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='zipnerf_image'><img src='images/MEStereo2.png' width="160">
            </video></div>
            <img src='images/MEStereo1.png' width="160">
          </div>
          <script type="text/javascript">
            function zipnerf_start() {
              document.getElementById('zipnerf_image').style.opacity = "1";
            }

            function zipnerf_stop() {
              document.getElementById('zipnerf_image').style.opacity = "0";
            }
            zipnerf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://link.springer.com/article/10.1007/s00371-023-02912-z">
            <span class="papertitle">MEStereo-Du2CNN: a dual-channel CNN for learning robust depth
estimates from multi-exposure stereo images for HDR 3D applications</span>
          </a>
          <br>
          <strong>Rohit Choudhary</strong>,
          <a href="https://www.linkedin.com/in/mansi-sharma-89942623/?originalSubdomain=in">Mansi Sharma</a>,
          <a href="https://www.linkedin.com/in/uma-t-v-5a7533149/?originalSubdomain=in">T.V. Uma</a>,
          <a href="https://www.linkedin.com/in/rithvik-anil/?originalSubdomain=in">Rithvik Anil</a>,
          <br>
          <em>The Visual Computer Journal</em>, 2023
          <br>
          <a href="https://link.springer.com/article/10.1007/s00371-023-02912-z">Paper link</a>
          /
          <a href="https://github.com/RohitChoudharyManth/MEStrereo-Du2CNN">Github page</a>
          /
          <a href="https://arxiv.org/abs/2206.10375">arXiv</a>
          /
          <a href="https://drive.google.com/file/d/1684NzIrXFLzSAutpW0wVr_hjEQ4kzwTl/view">Supplementary file</a>
          <p></p>
          <p>
           Exploring the utilization of a High Dynamic Range (HDR) reconstruction process to forecast depth, thereby opening up the potential of achieving 3D HDR through a unified pipeline.
          </p>
        </td>
      </tr>
      
      
      <tr onmouseout="db3d_stop()" onmouseover="db3d_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <div class="two" id='db3d_image'><img src='images/Elegan_bright.jpg' width="160"></div>
            <img src='images/Elegan_dark.jpg' width="160">
          </div>
          <script type="text/javascript">
            function db3d_start() {
              document.getElementById('db3d_image').style.opacity = "1";
            }

            function db3d_stop() {
              document.getElementById('db3d_image').style.opacity = "0";
            }
            db3d_stop()
          </script>
        </td>

        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://drive.google.com/file/d69/1fWc2KEWm3KLigQnI3u-81xG-g51ObCze/view?usp=sharing">
            <span class="papertitle">ELEGAN: An efficient low light enhancement for unpaired supervision</span>
          </a>
          <br>
          
  <strong>Rohit Choudhary</strong>, <a href="https://www.linkedin.com/in/harshith-reddy-thammineni-10515616b?originalSubdomain=in">T Harshith Reddy</a>, <a href="https://www.linkedin.com/in/mansi-sharma-89942623/?originalSubdomain=in">Mansi Sharma</a> 
          <br>
          <em>IEEE International Conference on Image Processing (ICIP)</em>, 2023
          <br>
          <a href="https://ieeexplore.ieee.org/document/10223080">Paper link</a> / 
          <a href="https://www.youtube.com/watch?v=5sSBskIqaKg">Presentation video</a>
          <p></p>
          <p>ELEGAN, a lightweight attention-guided generative adversarial network for fast low-light image enhancement in a fully unsupervised manner.
          </p>
        </td>
      </tr>

      

      <tr onmouseout="bakedsdf_stop()" onmouseover="bakedsdf_start()">
        <td style="padding:20px;width:25%;vertical-align:middle">
          <div class="one">
            <img src='images/SDE.png' width="160">
          </div>
          <script type="text/javascript">
            function bakedsdf_start() {
              document.getElementById('bakedsdf_image').style.opacity = "1";
            }

            function bakedsdf_stop() {
              document.getElementById('bakedsdf_image').style.opacity = "0";
            }
            bakedsdf_stop()
          </script>
        </td>
        <td style="padding:20px;width:75%;vertical-align:middle">
          <a href="https://ieeexplore.ieee.org/document/9675391/">
            <span class="papertitle">SDE-DualENet: A Novel Dual Efficient Convolutional Neural Network for Robust Stereo Depth Estimation</span>
          </a>
          <br>
          <a href="https://www.linkedin.com/in/rithvik-anil/?originalSubdomain=in">Rithvik Anil</a>,
          <a href="https://www.linkedin.com/in/mansi-sharma-89942623/?originalSubdomain=in">Mansi Sharma</a>,
          <strong>Rohit Choudhary</strong>
          <br>
          <em>IEEE Visual Communications and Image Processing (VCIP)</em>, 2023
          <br>
          <a href="https://ieeexplore.ieee.org/document/9675391/">Paper link</a>
          <p></p>
          <p>
          Eliminating cost-volume construction in stereo disparity estimation.
          </p>
        </td>
      </tr>


      
            <tr onmouseout="blocknerf_stop()" onmouseover="blocknerf_start()">
              <td style="padding:20px;width:25%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='blocknerf_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/NAC.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/NAC.png' width="160">
                </div>
                <script type="text/javascript">
                  function blocknerf_start() {
                    document.getElementById('blocknerf_image').style.opacity = "1";
                  }

                  function blocknerf_stop() {
                    document.getElementById('blocknerf_image').style.opacity = "0";
                  }
                  blocknerf_stop()
                </script>
              </td>
              <td style="padding:20px;width:75%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2206.11095">
                  <span class="papertitle">A High Resolution Multi-exposure Stereoscopic Image & Video Database of Natural Scenes</span>
                </a>
                <br>
                <strong>Rohit Choudhary</strong>,
                <a href="https://www.linkedin.com/in/mansi-sharma-89942623/?originalSubdomain=in">Mansi Sharma</a>,
                <a href="https://www.linkedin.com/in/aditya-wadaskar-876a1812a/?originalSubdomain=in">Aditya Wadaskar</a>
                <br>
          <em>arXiv</em>, 2022 &nbsp
                <br>
                <a href="https://sites.google.com/view/
multi-exposure-stereo-data/.">Webpge</a>
          /
                <a href="https://arxiv.org/abs/2206.11095">ArXiv</a>
                <p></p>
                <p>A diversified stereoscopic multi-exposure dataset captured within the campus of IIT Madras.</p>
              </td>
            </tr>
            


          </tbody></table>

          
            
            
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Website credits to <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
